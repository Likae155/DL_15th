{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PyTorch MNIST CNN\n",
                "\n",
                "This notebook demonstrates loading the MNIST dataset, performing EDA, and training a Convolutional Neural Network (CNN) using PyTorch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import torchvision\n",
                "import torchvision.transforms as transforms\n",
                "from torch.utils.data import DataLoader\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import numpy as np\n",
                "from sklearn.metrics import confusion_matrix\n",
                "\n",
                "# Check device\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Using device: {device}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading & Preprocessing\n",
                "We use `torchvision.datasets` to download MNIST. Images are converted to tensors and normalized."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.1307,), (0.3081,))\n",
                "])\n",
                "\n",
                "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
                "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
                "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
                "\n",
                "print(f'Train dataset size: {len(train_dataset)}')\n",
                "print(f'Test dataset size: {len(test_dataset)}')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Exploratory Data Analysis (EDA)\n",
                "Let's visualize a few images from the dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def imshow(img, title=None):\n",
                "    img = img * 0.3081 + 0.1307 # unnormalize\n",
                "    npimg = img.numpy()\n",
                "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
                "    if title:\n",
                "        plt.title(title)\n",
                "    plt.axis('off')\n",
                "\n",
                "dataiter = iter(train_loader)\n",
                "images, labels = next(dataiter)\n",
                "\n",
                "plt.figure(figsize=(10, 4))\n",
                "imshow(torchvision.utils.make_grid(images[:16], nrow=8), title='Sample MNIST Images')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. CNN Modeling\n",
                "Defining a simple Convolutional Neural Network architecture."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleCNN(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(SimpleCNN, self).__init__()\n",
                "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
                "        self.relu1 = nn.ReLU()\n",
                "        self.pool1 = nn.MaxPool2d(2, 2)\n",
                "        \n",
                "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
                "        self.relu2 = nn.ReLU()\n",
                "        self.pool2 = nn.MaxPool2d(2, 2)\n",
                "        \n",
                "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
                "        self.relu3 = nn.ReLU()\n",
                "        self.dropout = nn.Dropout(0.5)\n",
                "        self.fc2 = nn.Linear(128, 10)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.pool1(self.relu1(self.conv1(x)))\n",
                "        x = self.pool2(self.relu2(self.conv2(x)))\n",
                "        x = x.view(-1, 64 * 7 * 7)\n",
                "        x = self.relu3(self.fc1(x))\n",
                "        x = self.dropout(x)\n",
                "        x = self.fc2(x)\n",
                "        return x\n",
                "\n",
                "model = SimpleCNN().to(device)\n",
                "print(model)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training & Validation\n",
                "Training the model for 5 epochs and evaluating on the test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
                "\n",
                "epochs = 5\n",
                "train_losses = []\n",
                "test_losses = []\n",
                "test_accuracies = []\n",
                "\n",
                "for epoch in range(epochs):\n",
                "    model.train()\n",
                "    running_loss = 0.0\n",
                "    for images, labels in train_loader:\n",
                "        images, labels = images.to(device), labels.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(images)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        running_loss += loss.item() * images.size(0)\n",
                "        \n",
                "    epoch_train_loss = running_loss / len(train_loader.dataset)\n",
                "    train_losses.append(epoch_train_loss)\n",
                "    \n",
                "    # Validation loop\n",
                "    model.eval()\n",
                "    running_test_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    with torch.no_grad():\n",
                "        for images, labels in test_loader:\n",
                "            images, labels = images.to(device), labels.to(device)\n",
                "            outputs = model(images)\n",
                "            loss = criterion(outputs, labels)\n",
                "            running_test_loss += loss.item() * images.size(0)\n",
                "            \n",
                "            _, predicted = torch.max(outputs.data, 1)\n",
                "            total += labels.size(0)\n",
                "            correct += (predicted == labels).sum().item()\n",
                "            \n",
                "    epoch_test_loss = running_test_loss / len(test_loader.dataset)\n",
                "    test_losses.append(epoch_test_loss)\n",
                "    \n",
                "    accuracy = 100 * correct / total\n",
                "    test_accuracies.append(accuracy)\n",
                "    \n",
                "    print(f'Epoch {epoch+1}/{epochs} | Train Loss: {epoch_train_loss:.4f} | Test Loss: {epoch_test_loss:.4f} | Test Acc: {accuracy:.2f}%')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluation & Visualization\n",
                "Plotting learning curves and the confusion matrix."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 4))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
                "plt.plot(range(1, epochs+1), test_losses, label='Test Loss')\n",
                "plt.xlabel('Epochs')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "plt.title('Learning Curves')\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(range(1, epochs+1), test_accuracies, label='Test Accuracy', color='green')\n",
                "plt.xlabel('Epochs')\n",
                "plt.ylabel('Accuracy (%)')\n",
                "plt.legend()\n",
                "plt.title('Validation Accuracy')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.eval()\n",
                "all_preds = []\n",
                "all_targets = []\n",
                "with torch.no_grad():\n",
                "    for images, labels in test_loader:\n",
                "        images, labels = images.to(device), labels.to(device)\n",
                "        outputs = model(images)\n",
                "        _, predicted = torch.max(outputs.data, 1)\n",
                "        all_preds.extend(predicted.cpu().numpy())\n",
                "        all_targets.extend(labels.cpu().numpy())\n",
                "\n",
                "cm = confusion_matrix(all_targets, all_preds)\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.ylabel('True Label')\n",
                "plt.title('Confusion Matrix')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
