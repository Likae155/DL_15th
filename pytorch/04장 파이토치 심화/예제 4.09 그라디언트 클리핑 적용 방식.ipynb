{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7gngt5yqqjf",
   "source": "# 예제 4.09: 그라디언트 클리핑 (Gradient Clipping)\n\n## 학습목표\n1. **그라디언트 클리핑(Gradient Clipping)** 개념 이해하기\n2. **clip_grad_norm_** 함수 사용법 익히기\n3. **기울기 폭발 방지** 방법 학습하기\n\n---\n\n#### 그라디언트 클리핑 적용\n\n**그라디언트 클리핑이란?**\n- 기울기(gradient)의 크기를 제한\n- 기울기 폭발(Exploding Gradient) 방지\n- RNN, LSTM 등 순환 신경망에서 특히 중요\n\n**clip_grad_norm_(parameters, max_norm)**\n- parameters: 클리핑할 파라미터들\n- max_norm: 기울기의 최대 노름(norm) 값\n- 전체 기울기의 L2 노름이 max_norm을 초과하면 스케일링",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8af4d15-75d3-4b30-988a-d244842b0953",
   "metadata": {},
   "outputs": [],
   "source": "import torch\n\n# 그라디언트 클리핑이 적용된 학습 루프 (의사 코드)\n# 실제 사용 시 model, train_dataloader, criterion, device, optimizer 정의 필요\n\nfor x, y in train_dataloader:\n    x = x.to(device)\n    y = y.to(device)\n\n    output = model(x)\n    loss = criterion(output, y)\n    \n    # 기울기 초기화\n    optimizer.zero_grad()\n    \n    # 역전파: 기울기 계산\n    loss.backward()\n\n    # 그라디언트 클리핑 적용 (backward 후, step 전)\n    # max_norm=0.1: 기울기의 L2 노름을 0.1로 제한\n    # 기울기가 너무 크면 스케일링하여 안정적인 학습\n    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n\n    # 파라미터 업데이트\n    optimizer.step()\n    \n# 참고: clip_grad_value_도 있음 (값 자체를 제한)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}