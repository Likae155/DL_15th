{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ndt97kefayh",
   "source": "# 예제 4.06: L2 정칙화 (L2 Regularization)\n\n## 학습목표\n1. **L2 정칙화(Ridge)** 개념 이해하기\n2. **손실함수에 L2 페널티 추가** 방법 익히기\n3. **L1 vs L2 정칙화 차이점** 파악하기\n\n---\n\n#### L2 정칙화 적용\n\n**L2 정칙화란?**\n- 가중치의 제곱합을 손실함수에 추가\n- Loss = 원래 손실 + λ × Σw²\n- 특징: 가중치를 0에 가깝게 만들지만 정확히 0은 아님\n- 모든 특성을 사용하면서 과적합 방지\n\n**L1 vs L2 비교**\n- L1: 희소한 모델 (일부 가중치 = 0)\n- L2: 조밀한 모델 (모든 가중치 작은 값)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daae2f11-66a9-4f2b-90d6-4817b2aeb9e1",
   "metadata": {},
   "outputs": [],
   "source": "# L2 정칙화가 적용된 학습 루프 (의사 코드)\n# 실제 사용 시 model, train_dataloader, criterion, device, optimizer 정의 필요\n\nfor x, y in train_dataloader:\n    x = x.to(device)\n    y = y.to(device)\n\n    output = model(x)\n\n    # L2 정칙화 하이퍼파라미터\n    _lambda = 0.5\n    \n    # L2 손실 계산: 모든 파라미터의 제곱합\n    # p.pow(2.0): 각 파라미터의 제곱\n    # p.pow(2.0).sum(): 한 파라미터 텐서의 제곱합\n    # sum(...): 모든 파라미터에 대해 합산\n    l2_loss = sum(p.pow(2.0).sum() for p in model.parameters())\n\n    # 최종 손실 = 원래 손실 + λ × L2 손실\n    loss = criterion(output, y) + _lambda * l2_loss\n    \n    # 이후 역전파 및 최적화 수행\n    # optimizer.zero_grad()\n    # loss.backward()\n    # optimizer.step()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}