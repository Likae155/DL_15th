{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83rx6q20mp8",
   "source": "# 예제 4.05: L1 정칙화 (L1 Regularization)\n\n## 학습목표\n1. **L1 정칙화(Lasso)** 개념 이해하기\n2. **손실함수에 L1 페널티 추가** 방법 익히기\n3. **L1 정칙화의 효과** 파악하기 - 희소성(Sparsity) 유도\n\n---\n\n#### L1 정칙화 적용\n\n**L1 정칙화란?**\n- 가중치의 절댓값 합을 손실함수에 추가\n- Loss = 원래 손실 + λ × Σ|w|\n- 특징: 일부 가중치를 정확히 0으로 만듦 (희소성)\n- 특성 선택(Feature Selection) 효과\n\n**lambda (λ)**\n- 정칙화 강도를 조절하는 하이퍼파라미터\n- λ가 클수록 가중치가 더 작아짐 (과적합 방지)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f61458-0ab6-4471-8714-0cbb5a35adcd",
   "metadata": {},
   "outputs": [],
   "source": "# L1 정칙화가 적용된 학습 루프 (의사 코드)\n# 실제 사용 시 model, train_dataloader, criterion, device, optimizer 정의 필요\n\nfor x, y in train_dataloader:\n    x = x.to(device)\n    y = y.to(device)\n\n    output = model(x)\n\n    # L1 정칙화 하이퍼파라미터\n    _lambda = 0.5\n    \n    # L1 손실 계산: 모든 파라미터의 절댓값 합\n    # p.abs(): 각 파라미터의 절댓값\n    # p.abs().sum(): 한 파라미터 텐서의 절댓값 합\n    # sum(...): 모든 파라미터에 대해 합산\n    l1_loss = sum(p.abs().sum() for p in model.parameters())\n\n    # 최종 손실 = 원래 손실 + λ × L1 손실\n    loss = criterion(output, y) + _lambda * l1_loss\n    \n    # 이후 역전파 및 최적화 수행\n    # optimizer.zero_grad()\n    # loss.backward()\n    # optimizer.step()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}