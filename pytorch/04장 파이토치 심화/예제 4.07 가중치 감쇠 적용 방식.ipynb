{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1tvjnjtu11d",
   "source": "# 예제 4.07: 가중치 감쇠 (Weight Decay)\n\n## 학습목표\n1. **가중치 감쇠(Weight Decay)** 개념 이해하기\n2. **옵티마이저의 weight_decay 매개변수** 사용법 익히기\n3. **L2 정칙화와의 관계** 파악하기\n\n---\n\n#### 가중치 감쇠 적용\n\n**가중치 감쇠란?**\n- L2 정칙화를 옵티마이저에서 자동으로 적용\n- 수동으로 손실함수에 추가할 필요 없음\n- 가중치 업데이트 시 자동으로 감쇠 적용\n\n**weight_decay 매개변수**\n- SGD, Adam 등 대부분의 옵티마이저에서 지원\n- weight_decay=0.01 → 가중치에 0.01의 감쇠 적용",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a49a26-1f29-4af5-aa6c-cb9f397a2201",
   "metadata": {},
   "outputs": [],
   "source": "import torch\n\n# 가중치 감쇠가 적용된 옵티마이저 정의\n# weight_decay: L2 정칙화 강도 (0.01 = 1% 감쇠)\n# \n# 장점:\n# - 손실함수 수정 없이 간단히 적용 가능\n# - L2 정칙화와 동일한 효과\n# \n# 사용 예시 (model이 정의되어 있다고 가정):\n# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.01)\n\n# 가중치 감쇠 적용 예시\nprint(\"가중치 감쇠 옵티마이저 예시:\")\nprint(\"optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.01)\")\nprint(\"\\n다른 옵티마이저에서도 동일하게 사용:\")\nprint(\"optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}