{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "qabp25nmcgp",
   "source": "# 예제 3.29-3.33: 다중 선형 회귀\n\n## 학습목표\n1. **다중 선형 회귀** 개념 이해하기 - 여러 입력으로 여러 출력 예측\n2. **DataLoader와 TensorDataset** 사용법 익히기\n3. **배치(Batch) 학습** 방법 이해하기\n4. **미니배치 경사하강법** 구현하기\n\n---\n\n#### 예제 3.29-3.30 데이터 및 라이브러리 준비\n\n**다중 선형 회귀 (Multiple Linear Regression)**\n- 여러 개의 입력 변수로 출력을 예측\n- 예: 2개 입력 → 2개 출력",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83500a5b-a66c-4ede-8455-af9195e07db4",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nfrom torch import nn\nfrom torch import optim\n# TensorDataset: 텐서를 데이터셋으로 변환\n# DataLoader: 배치 단위로 데이터를 불러오는 유틸리티\nfrom torch.utils.data import TensorDataset, DataLoader \n\n# 훈련 데이터: 입력 2개, 출력 2개\n# train_x shape: (6, 2) - 6개 샘플, 각 샘플당 2개 특성\ntrain_x = torch.FloatTensor([\n    [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]\n])\n# train_y shape: (6, 2) - 6개 샘플, 각 샘플당 2개 타겟\ntrain_y = torch.FloatTensor([\n    [0.1, 1.5], [1, 2.8], [1.9, 4.1], [2.8, 5.4], [3.7, 6.7], [4.6, 8]\n])"
  },
  {
   "cell_type": "markdown",
   "id": "f5wmlmhjk6i",
   "source": "---\n\n#### 예제 3.31 데이터셋과 데이터로더 정의\n\n**DataLoader 매개변수**\n- `batch_size`: 한 번에 처리할 샘플 수\n- `shuffle`: 에포크마다 데이터 순서 섞기 (과적합 방지)\n- `drop_last`: 마지막 불완전한 배치 버리기",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b194de-ff26-49d3-8833-028bb2915c63",
   "metadata": {},
   "outputs": [],
   "source": "# TensorDataset: (입력, 타겟) 쌍으로 데이터셋 생성\ntrain_dataset = TensorDataset(train_x, train_y)\n\n# DataLoader: 배치 단위로 데이터 제공\n# batch_size=2: 한 번에 2개 샘플씩 처리\n# shuffle=True: 매 에포크마다 데이터 순서 무작위화\n# drop_last=True: 배치 크기에 맞지 않는 마지막 데이터 버림\ntrain_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True)"
  },
  {
   "cell_type": "markdown",
   "id": "w2vb8uot8hb",
   "source": "---\n\n#### 예제 3.32 모델 정의\n\n**nn.Linear(in_features, out_features, bias)**\n- in_features=2: 입력 차원 (2개 특성)\n- out_features=2: 출력 차원 (2개 타겟)\n- bias=True: 편향 사용",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac12a376-35c5-4ac9-a355-0d7919f7e6f4",
   "metadata": {},
   "outputs": [],
   "source": "# 모델: 입력 2개 → 출력 2개 (bias=True로 편향 사용)\nmodel = nn.Linear(2, 2, bias=True)\n\n# 손실함수: MSE\ncriterion = nn.MSELoss()\n\n# 옵티마이저: SGD\noptimizer = optim.SGD(model.parameters(), lr=0.001)"
  },
  {
   "cell_type": "markdown",
   "id": "z7kx2c8zx87",
   "source": "---\n\n#### 예제 3.33 미니배치 학습\n\n**미니배치 경사하강법**\n- 전체 데이터를 작은 배치로 나누어 학습\n- 메모리 효율적, 더 빠른 수렴 가능",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee590b-d644-4c65-b361-a65b848a7296",
   "metadata": {},
   "outputs": [],
   "source": "# 미니배치 학습 루프\nfor epoch in range(20000):\n    cost = 0.0  # 에포크별 총 손실\n    \n    # DataLoader가 배치 단위로 데이터 제공\n    for batch in train_dataloader:\n        x, y = batch  # 배치에서 입력과 타겟 분리\n        output = model(x)  # 순전파\n        \n        loss = criterion(output, y)  # 손실 계산\n        \n        optimizer.zero_grad()  # 기울기 초기화\n        loss.backward()        # 역전파\n        optimizer.step()       # 파라미터 업데이트\n        \n        cost += loss  # 배치 손실 누적\n\n    # 평균 손실 계산 (총 손실 / 배치 수)\n    cost = cost / len(train_dataloader)\n    \n    if (epoch + 1) % 1000 == 0:\n        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}