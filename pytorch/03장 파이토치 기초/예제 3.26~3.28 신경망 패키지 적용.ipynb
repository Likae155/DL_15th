{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ejjzsxnz59",
   "source": "# 예제 3.26-3.28: 신경망 패키지(nn) 적용\n\n## 학습목표\n1. **torch.nn 모듈** 사용법 익히기 - 신경망 레이어 정의\n2. **nn.Linear** 를 사용한 선형 레이어 구성하기\n3. **nn.MSELoss** 손실함수 사용법 학습하기\n4. **model.parameters()** 로 학습 파라미터 관리하기\n\n---\n\n#### 예제 3.26 라이브러리 임포트\n\n**torch.nn 모듈**\n- 신경망 구성 요소를 제공하는 핵심 모듈\n- Linear, Conv2d, LSTM 등 다양한 레이어 제공\n- MSELoss, CrossEntropyLoss 등 손실함수 제공",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c4e13c-31d5-44c4-b726-370b1f662f10",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nfrom torch import nn     # 신경망 모듈 (레이어, 손실함수 등)\nfrom torch import optim  # 옵티마이저 모듈"
  },
  {
   "cell_type": "markdown",
   "id": "vk2ytz573ed",
   "source": "---\n\n#### 데이터 준비",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c387cb7",
   "metadata": {},
   "outputs": [],
   "source": "# 입력 데이터 x와 출력 데이터 y\nx = torch.FloatTensor([\n    [1], [2], [3], [4], [5], [6], [7], [8], [9], [10],\n    [11], [12], [13], [14], [15], [16], [17], [18], [19], [20],\n    [21], [22], [23], [24], [25], [26], [27], [28], [29], [30]\n])\ny = torch.FloatTensor([\n    [0.94], [1.98], [2.88], [3.92], [3.96], [4.55], [5.64], [6.3], [7.44], [9.1],\n    [8.46], [9.5], [10.67], [11.16], [14], [11.83], [14.4], [14.25], [16.2], [16.32],\n    [17.46], [19.8], [18], [21.34], [22], [22.5], [24.57], [26.04], [21.6], [28.8]\n])"
  },
  {
   "cell_type": "markdown",
   "id": "orwxmcz825",
   "source": "---\n\n#### 예제 3.27 모델, 손실함수, 옵티마이저 정의\n\n**nn.Linear(in_features, out_features)**\n- 선형 변환 레이어: y = xW^T + b\n- in_features: 입력 차원\n- out_features: 출력 차원\n\n**nn.MSELoss()**\n- 평균제곱오차(Mean Squared Error) 손실함수",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40fb176-5f47-46f0-97ae-deedf8cf4e4f",
   "metadata": {},
   "outputs": [],
   "source": "# 모델 정의: 입력 1개 → 출력 1개인 선형 레이어\nmodel = nn.Linear(1, 1)\n\n# 손실함수: MSE (평균제곱오차)\ncriterion = nn.MSELoss()\n\n# 옵티마이저: model.parameters()로 모델의 모든 학습 파라미터 전달\noptimizer = optim.SGD(model.parameters(), lr=0.001)"
  },
  {
   "cell_type": "markdown",
   "id": "n5ep0fcc91j",
   "source": "---\n\n#### 예제 3.28 학습 루프\n\n**모델 사용 방법**\n- `model(x)`: 순전파 수행 (예측값 계산)\n- `list(model.parameters())`: 학습된 가중치와 편향 확인",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e553a7d",
   "metadata": {},
   "outputs": [],
   "source": "# 학습 루프\nfor epoch in range(10000):\n    # 순전파: 모델에 입력을 넣어 예측값 계산\n    output = model(x)\n    \n    # 손실 계산: criterion(예측값, 정답)\n    cost = criterion(output, y)\n\n    # 역전파 및 파라미터 업데이트\n    optimizer.zero_grad()  # 기울기 초기화\n    cost.backward()        # 역전파\n    optimizer.step()       # 파라미터 업데이트\n\n    # 1000 에포크마다 진행상황 출력\n    if (epoch + 1) % 1000 == 0:\n        # model.parameters(): [weight, bias] 반환\n        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}